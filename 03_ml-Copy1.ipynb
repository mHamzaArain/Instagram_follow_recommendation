{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "naWvqMEMHglO"
   },
   "source": [
    "<p style=\"font-size:32px;text-align:center\"> <b>Social network Graph Link Prediction - Facebook Challenge</b> </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9wb9N5RzHglP"
   },
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "# please do go through this python notebook: \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import csv\n",
    "import pandas as pd#pandas to create small dataframes \n",
    "import datetime #Convert to unix time\n",
    "import time #Convert to unix time\n",
    "# if numpy is not installed already : pip3 install numpy\n",
    "import numpy as np#Do aritmetic operations on arrays\n",
    "# matplotlib: used to plot graphs\n",
    "import matplotlib\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns#Plots\n",
    "from matplotlib import rcParams#Size of plots  \n",
    "from sklearn.cluster import MiniBatchKMeans, KMeans#Clustering\n",
    "import math\n",
    "import pickle\n",
    "import os\n",
    "# to install xgboost: pip3 install xgboost\n",
    "import xgboost as xgb\n",
    "\n",
    "import warnings\n",
    "import networkx as nx\n",
    "import pdb\n",
    "import pickle\n",
    "from pandas import HDFStore,DataFrame\n",
    "from pandas import read_hdf\n",
    "from scipy.sparse.linalg import svds, eigs\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "Ys0vdQrY2kAz",
    "outputId": "f22fe2fc-b7d7-4661-c472-8060963b3575"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B88FnwwO2l9p"
   },
   "outputs": [],
   "source": [
    "# dir_path='/content/drive/My Drive/Colab Notebooks/AppliedAI/Facebook_Assignment/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(test_y, predict_y):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    C = confusion_matrix(test_y, predict_y)\n",
    "    \n",
    "    A =(((C.T)/(C.sum(axis=1))).T)\n",
    "    \n",
    "    B =(C/C.sum(axis=0))\n",
    "    plt.figure(figsize=(20,4))\n",
    "    \n",
    "    labels = [0,1]\n",
    "    # representing A in heatmap format\n",
    "    cmap=sns.light_palette(\"blue\")\n",
    "    plt.subplot(1, 3, 1)\n",
    "    sns.heatmap(C, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    sns.heatmap(B, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.title(\"Precision matrix\")\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    # representing B in heatmap format\n",
    "    sns.heatmap(A, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.title(\"Recall matrix\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XC4OJFKkHglU"
   },
   "outputs": [],
   "source": [
    "#reading\n",
    "from pandas import read_hdf\n",
    "# df_final_train = read_hdf(dir_path+'data/fea_sample/storage_sample_stage4.h5',\n",
    "#                           'train_df',mode='r')\n",
    "# df_final_test = read_hdf(dir_path+'data/fea_sample/storage_sample_stage4.h5',\n",
    "#                          'test_df',mode='r')\n",
    "\n",
    "df_final_train = read_hdf('data/fea_sample/storage_sample_stage4.h5',\n",
    "                          'train_df',mode='r')\n",
    "df_final_test = read_hdf('data/fea_sample/storage_sample_stage4.h5',\n",
    "                         'test_df',mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "5Gm-BHRkHglW",
    "outputId": "155ca8d8-67a0-411f-a6f7-40c82b59c3c7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['source_node', 'destination_node', 'indicator_link',\n",
       "       'jaccard_followers', 'jaccard_followees', 'cosine_followers',\n",
       "       'cosine_followees', 'num_followers_s', 'num_followers_d',\n",
       "       'num_followees_s', 'num_followees_d', 'inter_followers',\n",
       "       'inter_followees', 'adar_index', 'follows_back', 'same_comp',\n",
       "       'shortest_path', 'weight_in', 'weight_out', 'weight_f1', 'weight_f2',\n",
       "       'weight_f3', 'weight_f4', 'page_rank_s', 'page_rank_d', 'katz_s',\n",
       "       'katz_d', 'hubs_s', 'hubs_d', 'authorities_s', 'authorities_d',\n",
       "       'svd_u_s_1', 'svd_u_s_2', 'svd_u_s_3', 'svd_u_s_4', 'svd_u_s_5',\n",
       "       'svd_u_s_6', 'svd_u_d_1', 'svd_u_d_2', 'svd_u_d_3', 'svd_u_d_4',\n",
       "       'svd_u_d_5', 'svd_u_d_6', 'svd_v_s_1', 'svd_v_s_2', 'svd_v_s_3',\n",
       "       'svd_v_s_4', 'svd_v_s_5', 'svd_v_s_6', 'svd_v_d_1', 'svd_v_d_2',\n",
       "       'svd_v_d_3', 'svd_v_d_4', 'svd_v_d_5', 'svd_v_d_6'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XRW7VZ4AHglc"
   },
   "outputs": [],
   "source": [
    "y_train = df_final_train.indicator_link\n",
    "y_test = df_final_test.indicator_link\n",
    "\n",
    "df_final_train.drop(['source_node', 'destination_node','indicator_link'],\n",
    "                    axis=1,inplace=True)\n",
    "df_final_test.drop(['source_node', 'destination_node','indicator_link'],\n",
    "                   axis=1,inplace=True)\n",
    "\n",
    "x_train = df_final_train\n",
    "x_test = df_final_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BestMLAlgo(x_train, x_test, y_train, y_test):\n",
    "    \"\"\"Identify best Algo on given dataset\"\"\"\n",
    "    from prettytable import PrettyTable\n",
    "    \n",
    "    table = PrettyTable()\n",
    "    table.field_names = [\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1Score\", \"Log loss\", \"auc_score\"]\n",
    "                        \n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.ensemble import AdaBoostClassifier\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    from sklearn.linear_model import SGDClassifier\n",
    "    from sklearn.calibration import CalibratedClassifierCV\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "    import xgboost\n",
    "    from sklearn import svm\n",
    "    from sklearn.metrics import precision_score, accuracy_score, roc_auc_score,\\\n",
    "                                roc_curve, auc, log_loss, recall_score\n",
    "    \n",
    "    base_models = {\n",
    "        'kNN': KNeighborsClassifier(),\n",
    "        'Naive Bayes': MultinomialNB(),\n",
    "        'Log. Reg.': LogisticRegression(),\n",
    "        'SVM Linear': SGDClassifier(class_weight='balanced', penalty='l2', loss='hinge', random_state=42),\n",
    "        'SVM Non-linear': svm.SVC(kernel='rbf'),\n",
    "        'Decision Tree': DecisionTreeClassifier(),\n",
    "        'Random Forest': RandomForestClassifier(),\n",
    "        'Gradient Boost': GradientBoostingClassifier(),\n",
    "        'Ada Boost': AdaBoostClassifier(),\n",
    "        'xgboost': xgboost.XGBClassifier(),\n",
    "    }              \n",
    "    for model_name, model in base_models.items():\n",
    "        try:\n",
    "            model.fit(x_train, y_train)\n",
    "            model = CalibratedClassifierCV(model, method=\"sigmoid\")\n",
    "            model.fit(x_train, y_train)\n",
    "            y_pred_proba = model.predict_proba(x_test)\n",
    "            y_pred = model.predict(x_test)\n",
    "\n",
    "            # Performance metrics\n",
    "                    # Performance metrics\n",
    "            accuracy        = round(accuracy_score(y_test, y_pred), 2)\n",
    "            precision       = round(precision_score(y_test, y_pred, average='micro'), 2)\n",
    "            recall          = round(recall_score(y_test, y_pred, average='micro'), 2)\n",
    "            f1_score        = round((2*recall*precision)/(recall+precision), 2)\n",
    "            loss            = round(log_loss(y_test, y_pred_proba, labels=[0, 1],  eps=1e-15), 2) # , labels=model.classes\n",
    "\n",
    "            fpr, tpr, thresholds = roc_curve(y_test, y_pred, pos_label=1)\n",
    "\n",
    "            auc_score = round(auc(fpr, tpr), 2)      \n",
    "\n",
    "            table.add_row([model_name, accuracy, precision, recall, f1_score, loss, auc_score])\n",
    "        except:\n",
    "            pass\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BestMLAlgo(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lIEc91uVHgli",
    "outputId": "31f04b72-ebe5-4b13-ccca-a5ae3bc4f09c"
   },
   "outputs": [],
   "source": [
    "estimators = [10,50,100,250,450]\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for i in estimators:\n",
    "    clf = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=52, min_samples_split=120,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=i, n_jobs=-1,random_state=25,verbose=0,warm_start=False)\n",
    "    clf.fit(df_final_train,y_train)\n",
    "    train_sc = f1_score(y_train,clf.predict(df_final_train))\n",
    "    test_sc = f1_score(y_test,clf.predict(df_final_test))\n",
    "    test_scores.append(test_sc)\n",
    "    train_scores.append(train_sc)\n",
    "    print('Estimators = ',i,'Train Score',train_sc,'test Score',test_sc)\n",
    "plt.plot(estimators,train_scores,label='Train Score')\n",
    "plt.plot(estimators,test_scores,label='Test Score')\n",
    "plt.xlabel('Estimators')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Estimators vs score at depth of 5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nZxhrTdQHglm",
    "outputId": "53382b8e-148d-4c22-8066-d9807fb27012"
   },
   "outputs": [],
   "source": [
    "depths = [3,9,11,15,20,35,50,70,130]\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for i in depths:\n",
    "    clf = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=i, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=52, min_samples_split=120,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=115, n_jobs=-1,random_state=25,verbose=0,warm_start=False)\n",
    "    clf.fit(df_final_train,y_train)\n",
    "    train_sc = f1_score(y_train,clf.predict(df_final_train))\n",
    "    test_sc = f1_score(y_test,clf.predict(df_final_test))\n",
    "    test_scores.append(test_sc)\n",
    "    train_scores.append(train_sc)\n",
    "    print('depth = ',i,'Train Score',train_sc,'test Score',test_sc)\n",
    "plt.plot(depths,train_scores,label='Train Score')\n",
    "plt.plot(depths,test_scores,label='Test Score')\n",
    "plt.xlabel('Depth')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Depth vs score at depth of 5 at estimators = 115')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aO21ynhU3iOH"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MrG1Lfl3Hglq",
    "outputId": "7b6e3c97-8d66-455d-cd79-213f824719cc"
   },
   "outputs": [],
   "source": [
    "param_dist = {\"n_estimators\":sp_randint(105,125),\n",
    "              \"max_depth\": sp_randint(10,15),\n",
    "              \"min_samples_split\": sp_randint(110,190),\n",
    "              \"min_samples_leaf\": sp_randint(25,65)}\n",
    "\n",
    "clf = RandomForestClassifier(random_state=25,n_jobs=-1)\n",
    "\n",
    "rf_random = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=5,cv=10,scoring='f1',random_state=25)\n",
    "\n",
    "rf_random.fit(df_final_train,y_train)\n",
    "print('mean test scores',rf_random.cv_results_['mean_test_score'])\n",
    "print('mean train scores',rf_random.cv_results_['mean_train_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hme3j_diHglu",
    "outputId": "581ccc02-7770-4a94-d003-257af4e81570"
   },
   "outputs": [],
   "source": [
    "print(rf_random.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qu4KIEweHglx"
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=14, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=28, min_samples_split=111,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=121, n_jobs=-1,\n",
    "            oob_score=False, random_state=25, verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dax83GfLHgl1"
   },
   "outputs": [],
   "source": [
    "clf.fit(df_final_train,y_train)\n",
    "y_train_pred = clf.predict(df_final_train)\n",
    "y_test_pred = clf.predict(df_final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PTtAp1iTHgl4",
    "outputId": "e2e3d725-3c4d-4374-d303-8f294b570977"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print('Train f1 score',f1_score(y_train,y_train_pred))\n",
    "print('Test f1 score',f1_score(y_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5XfUkZYQHgl7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s6t11dhTHgl-",
    "outputId": "189de3be-1c99-4653-f56f-12b18b0f4db7"
   },
   "outputs": [],
   "source": [
    "print('Train confusion_matrix')\n",
    "plot_confusion_matrix(y_train,y_train_pred)\n",
    "print('Test confusion_matrix')\n",
    "plot_confusion_matrix(y_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "61TF-VLeHgmD",
    "outputId": "795f1b39-61c7-470f-e2d0-1fe6dc7ac5fd"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr,tpr,ths = roc_curve(y_test,y_test_pred)\n",
    "auc_sc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, color='navy',label='ROC curve (area = %0.2f)' % auc_sc)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic with test data')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HEZ7uvN6HgmK",
    "outputId": "6f762256-54fc-4e2f-865b-22342033eb2c"
   },
   "outputs": [],
   "source": [
    "features = df_final_train.columns\n",
    "importances = clf.feature_importances_\n",
    "indices = (np.argsort(importances))[-25:]\n",
    "plt.figure(figsize=(10,12))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='r', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xdHW32hcHgmN"
   },
   "source": [
    "# Assignments:\n",
    "\n",
    "1. Add another feature called  Preferential Attachment  with followers and followees data of vertex. you can check about Preferential Attachment in below link\n",
    "http://be.amazd.com/link-prediction/ <br>\n",
    "2. Add  feature called svd_dot. you can calculate svd_dot as Dot product between sourse node svd and destination node svd features.  you can read about this in below pdf \n",
    "https://storage.googleapis.com/kaggle-forum-message-attachments/2594/supervised_link_prediction.pdf<br>\n",
    "3. Tune hyperparameters for XG boost with all these features and check the error metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t50f9eb_9k9c"
   },
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pf6hie1R-LoH"
   },
   "outputs": [],
   "source": [
    "table = PrettyTable(field_names=['Model', 'Train F1', 'Test F1'])\n",
    "table.add_row(['RandomForestClassifier',round(0.9652533106548414,3),\n",
    "                              round(0.9241678239279553, 3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WsXxTRDz2SPd"
   },
   "outputs": [],
   "source": [
    "# Adding new feature 'Preferential Attachment'\n",
    "\n",
    "# We are getting error \"'Series' object has no attribute 'num_followers_d'\"\n",
    "# It seems the column num_followers_d was not saved properly, so we have to \n",
    "# recalculate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "Y2qcff1N_g-N",
    "outputId": "271cc5f4-1699-43d1-940b-08ec149d5815"
   },
   "outputs": [],
   "source": [
    "# Old code from FB_featurization.ipynb\n",
    "\n",
    "if os.path.isfile(dir_path+'data/after_eda/train_pos_after_eda.csv'):\n",
    "    train_graph=nx.read_edgelist(dir_path+'data/after_eda/train_pos_after_eda.csv',delimiter=',',create_using=nx.DiGraph(),nodetype=int)\n",
    "    print(nx.info(train_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YvRlayl7_1gd"
   },
   "outputs": [],
   "source": [
    "def compute_features_stage1(df_final):\n",
    "    #calculating no of followers followees for source and destination\n",
    "    #calculating intersection of followers and followees for source \n",
    "    #and destination\n",
    "    num_followers_s=[]\n",
    "    num_followees_s=[]\n",
    "    num_followers_d=[]\n",
    "    num_followees_d=[]\n",
    "    inter_followers=[]\n",
    "    inter_followees=[]\n",
    "    for i,row in df_final.iterrows():\n",
    "        try:\n",
    "            s1=set(train_graph.predecessors(row['source_node']))\n",
    "            s2=set(train_graph.successors(row['source_node']))\n",
    "        except:\n",
    "            s1 = set()\n",
    "            s2 = set()\n",
    "        try:\n",
    "            d1=set(train_graph.predecessors(row['destination_node']))\n",
    "            d2=set(train_graph.successors(row['destination_node']))\n",
    "        except:\n",
    "            d1 = set()\n",
    "            d2 = set()\n",
    "        num_followers_s.append(len(s1))\n",
    "        num_followees_s.append(len(s2))\n",
    "\n",
    "        num_followers_d.append(len(d1))\n",
    "        num_followees_d.append(len(d2))\n",
    "\n",
    "        inter_followers.append(len(s1.intersection(d1)))\n",
    "        inter_followees.append(len(s2.intersection(d2)))\n",
    "    \n",
    "    return num_followers_s, num_followers_d, num_followees_s,\\\n",
    "                num_followees_d, inter_followers, inter_followees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C_C2bB-iBCgV"
   },
   "outputs": [],
   "source": [
    "df_final_train['num_followers_s'], df_final_train['num_followers_d'], \\\n",
    "df_final_train['num_followees_s'], df_final_train['num_followees_d'], \\\n",
    "df_final_train['inter_followers'], df_final_train['inter_followees']= \\\n",
    "                                compute_features_stage1(df_final_train)\n",
    "\n",
    "df_final_test['num_followers_s'], df_final_test['num_followers_d'], \\\n",
    "df_final_test['num_followees_s'], df_final_test['num_followees_d'], \\\n",
    "df_final_test['inter_followers'], df_final_test['inter_followees']= \\\n",
    "                                compute_features_stage1(df_final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 530
    },
    "colab_type": "code",
    "id": "sZOtY57CCOI0",
    "outputId": "80813650-3f4f-47b3-bd77-b6a3f884d2e2"
   },
   "outputs": [],
   "source": [
    "print(df_final_train.columns)\n",
    "print('-'*100)\n",
    "print(df_final_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HYtGR5RuDL3g"
   },
   "outputs": [],
   "source": [
    "# Now to re-run the initial code from above\n",
    "\n",
    "y_train = df_final_train.indicator_link\n",
    "y_test = df_final_test.indicator_link\n",
    "df_final_train.drop(['source_node', 'destination_node','indicator_link'],\n",
    "                    axis=1,inplace=True)\n",
    "df_final_test.drop(['source_node', 'destination_node','indicator_link'],\n",
    "                   axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6pJ1dgxb4pm1"
   },
   "outputs": [],
   "source": [
    "df_final_train['pref_attach']=df_final_train.apply(lambda row:\\\n",
    "                            row.num_followers_s*row.num_followers_d,axis=1)\n",
    "df_final_test['pref_attach']=df_final_test.apply(lambda row:\\\n",
    "                            row.num_followers_s*row.num_followers_d,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DGTmj5lG2WFy"
   },
   "outputs": [],
   "source": [
    "# Adding the SVD Dot features\n",
    "\n",
    "df_final_train['svd_dot_u']=df_final_train.apply(lambda row:np.dot(row[['svd_u_s_1',\n",
    "              'svd_u_s_2','svd_u_s_3', 'svd_u_s_4', 'svd_u_s_5', 'svd_u_s_6']],\\\n",
    "            row[['svd_u_d_1', 'svd_u_d_2', 'svd_u_d_3', 'svd_u_d_4', 'svd_u_d_5',\n",
    "                 'svd_u_d_6']]),axis=1)\n",
    "df_final_train['svd_dot_v']=df_final_train.apply(lambda row:np.dot(row[['svd_v_s_1',\n",
    "              'svd_v_s_2', 'svd_v_s_3', 'svd_v_s_4', 'svd_v_s_5', 'svd_v_s_6']],\\\n",
    "            row[['svd_v_d_1', 'svd_v_d_2', 'svd_v_d_3', 'svd_v_d_4', 'svd_v_d_5',\n",
    "                 'svd_v_d_6']]),axis=1)\n",
    "df_final_test['svd_dot_u']=df_final_test.apply(lambda row:np.dot(row[['svd_u_s_1',\n",
    "              'svd_u_s_2','svd_u_s_3', 'svd_u_s_4', 'svd_u_s_5', 'svd_u_s_6']],\\\n",
    "            row[['svd_u_d_1', 'svd_u_d_2', 'svd_u_d_3', 'svd_u_d_4', 'svd_u_d_5',\n",
    "                 'svd_u_d_6']]),axis=1)\n",
    "df_final_test['svd_dot_v']=df_final_test.apply(lambda row:np.dot(row[['svd_v_s_1',\n",
    "              'svd_v_s_2', 'svd_v_s_3', 'svd_v_s_4', 'svd_v_s_5', 'svd_v_s_6']],\\\n",
    "            row[['svd_v_d_1', 'svd_v_d_2', 'svd_v_d_3', 'svd_v_d_4', 'svd_v_d_5',\n",
    "                 'svd_v_d_6']]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qRppdnv3fA-i"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection  import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "IIAqhWT4MsyJ",
    "outputId": "9784c11b-ad26-4c1a-b4e5-d4483b9ef7e2"
   },
   "outputs": [],
   "source": [
    "# Using the XGBoost params from the NYC Taxi assignment\n",
    "\n",
    "search_Params = {\n",
    "        'max_depth' : [3,7,13,19,25,31],\n",
    "        'subsample':[0.7, 0.8, 0.9],\n",
    "        'min_child_weight':[3, 5, 7, 9],\n",
    "        'n_estimators':[10,20,40,60,100],\n",
    "        'reg_lambda':[50,100,200,300],\n",
    "        }\n",
    "\n",
    "\n",
    "reg_XGB = xgb.XGBClassifier(n_jobs=-1, random_state=123)\n",
    "randomSearch = RandomizedSearchCV(reg_XGB, search_Params,\n",
    "                    scoring='f1',cv=7,n_jobs=-1)\n",
    "randomSearch.fit(df_final_train, y_train)\n",
    "\n",
    "print(randomSearch.best_estimator_)\n",
    "print(randomSearch.best_params_)\n",
    "print(randomSearch.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gutu2kNweXwo"
   },
   "outputs": [],
   "source": [
    "reg_XGB_opt = xgb.XGBClassifier(n_jobs=-1, random_state=123, max_depth=25,\n",
    "                        min_child_weight=5, n_estimators=60, reg_lambda=50,\n",
    "                        subsample=0.8).fit(df_final_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c_b0u63EeYWn"
   },
   "outputs": [],
   "source": [
    "# Train and Test prediction using the new features and XGBoost\n",
    "y_train_pred = reg_XGB_opt.predict(df_final_train)\n",
    "y_test_pred = reg_XGB_opt.predict(df_final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "LOXQYyXD8yMW",
    "outputId": "08e75977-d8b6-4393-e327-bb707ac4743b"
   },
   "outputs": [],
   "source": [
    "print('Train f1 score',f1_score(y_train,y_train_pred))\n",
    "print('Test f1 score',f1_score(y_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YYoW2mtj-8v0"
   },
   "outputs": [],
   "source": [
    "table.add_row(['XGBClassifier',round(0.9828574883852178,3),\n",
    "                              round(0.9332630246783379, 3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 627
    },
    "colab_type": "code",
    "id": "IlKo1ZMw8yIa",
    "outputId": "60ae0f75-48f2-444c-a792-39eedefc8ce8"
   },
   "outputs": [],
   "source": [
    "print('Train confusion_matrix')\n",
    "plot_confusion_matrix(y_train,y_train_pred)\n",
    "print('Test confusion_matrix')\n",
    "plot_confusion_matrix(y_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "QRgMH_Kd8xos",
    "outputId": "90d2cf51-d877-4d4b-bbff-55f801364429"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr,tpr,ths = roc_curve(y_test,y_test_pred)\n",
    "auc_sc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, color='navy',label='ROC curve (area = %0.2f)' % auc_sc)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic with test data')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 730
    },
    "colab_type": "code",
    "id": "PdFPaw-a9DD-",
    "outputId": "deeca9bf-be53-46fc-cd4e-964bdf9a2957"
   },
   "outputs": [],
   "source": [
    "features = df_final_train.columns\n",
    "importances = reg_XGB_opt.feature_importances_\n",
    "indices = (np.argsort(importances))[-25:]\n",
    "plt.figure(figsize=(10,12))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='r', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C9wIf8Qx9C_e"
   },
   "outputs": [],
   "source": [
    "# The feature importance graph tells us the two new added features have hardly\n",
    "# any significant impact in improving the score of the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "oYrL83fl-7E5",
    "outputId": "02741e20-3886-41fd-b5cb-01ecf5987879"
   },
   "outputs": [],
   "source": [
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kMKlGOcq_FZV"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "FB_Models.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
